{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding space visualization | Fiftyone experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = foz.load_zoo_dataset(\"mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split = dataset.match_tags(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing image embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import fiftyone.brain as fob\n",
    "\n",
    "# Construct a ``num_samples x num_pixels`` array of images\n",
    "embeddings = np.array([\n",
    "    cv2.imread(f, cv2.IMREAD_UNCHANGED).ravel()\n",
    "    for f in test_split.values(\"filepath\")\n",
    "])\n",
    "\n",
    "# Compute 2D representation\n",
    "results = fob.compute_visualization(\n",
    "    test_split,\n",
    "    embeddings=embeddings,\n",
    "    num_dims=2,\n",
    "    method=\"umap\",\n",
    "    brain_key=\"mnist_test\",\n",
    "    verbose=True,\n",
    "    seed=51,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(results))\n",
    "print(results.points.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch App instance\n",
    "session = fo.launch_app(view=test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot embeddings colored by ground truth label\n",
    "plot = results.visualize(labels=\"ground_truth.label\")\n",
    "plot.show(height=720)\n",
    "\n",
    "# Attach plot to session\n",
    "session.plots.attach(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-annotation of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a ``num_samples x num_pixels`` array of images\n",
    "embeddings = np.array([\n",
    "    cv2.imread(f, cv2.IMREAD_UNCHANGED).ravel()\n",
    "    for f in dataset.values(\"filepath\")\n",
    "])\n",
    "\n",
    "# Compute 2D representation\n",
    "results = fob.compute_visualization(\n",
    "    dataset,\n",
    "    embeddings=embeddings,\n",
    "    num_dims=2,\n",
    "    method=\"umap\",\n",
    "    brain_key=\"mnist\",\n",
    "    verbose=True,\n",
    "    seed=51,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fiftyone import ViewField as F\n",
    "\n",
    "# Label `test` split samples by their ground truth label\n",
    "# Mark all samples in `train` split as `unlabeled`\n",
    "expr = F(\"$tags\").contains(\"test\").if_else(F(\"label\"), \"unlabeled\")\n",
    "labels = dataset.values(\"ground_truth\", expr=expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch a new App instance\n",
    "session = fo.launch_app(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "plot = results.visualize(labels=labels)\n",
    "plot.show(height=720)\n",
    "\n",
    "# Attach plot to session\n",
    "session.plots.attach(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPLORING IMAGE UNIQUENESS WITH FIFTYONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Finding duplicate and near-duplicate images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "\n",
    "# Load the CIFAR-10 test split\n",
    "# Downloads the dataset from the web if necessary\n",
    "dataset = foz.load_zoo_dataset(\"cifar10\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset)\n",
    "session = fo.launch_app(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute uniqueness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone.brain as fob\n",
    "\n",
    "fob.compute_uniqueness(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the samples have a \"uniqueness\" field on them\n",
    "print(dataset)\n",
    "print(dataset.first())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize to find duplicate and near-duplicate images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort in increasing order of uniqueness (least unique first)\n",
    "dups_view = dataset.sort_by(\"uniqueness\")\n",
    "\n",
    "# Open view in the App\n",
    "session.view = dups_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get currently selected images from App\n",
    "dup_ids = session.selected\n",
    "\n",
    "# Mark as duplicates\n",
    "dups_view = dataset.select(dup_ids)\n",
    "dups_view.tag_samples(\"dups\")\n",
    "\n",
    "# Visualize duplicates-only in App\n",
    "session.view = dups_view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Bootstrapping a dataset of unique samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "\n",
    "data_basedir = '/home/lcondados/workspace/data/greiburg_groceries/freiburg_groceries_dataset/images'\n",
    "dataset = fo.Dataset.from_images_dir(data_basedir, recursive=True, name=\"groceries\")\n",
    "\n",
    "print(dataset)\n",
    "print(dataset.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = fo.launch_app(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute uniqueness and analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone.brain as fob\n",
    "\n",
    "fob.compute_uniqueness(dataset)\n",
    "\n",
    "# Now the samples have a \"uniqueness\" field on them\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by uniqueness (most unique first)\n",
    "rank_view = dataset.sort_by(\"uniqueness\", reverse=True)\n",
    "\n",
    "# Visualize in the App\n",
    "session.view = rank_view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, just visualizing the samples is interesting, but we want more. We want to get the most unique samples from our dataset so that we can use them in our work. Letâ€™s do just that. In the same Python session, execute the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that the most unique sample has the maximal uniqueness of 1.0\n",
    "print(rank_view.first())\n",
    "\n",
    "# Extract paths to 10 most unique samples\n",
    "ten_best = [x.filepath for x in rank_view.limit(10)]\n",
    "\n",
    "for filepath in ten_best:\n",
    "    print(filepath.split('/')[-1])\n",
    "\n",
    "# Then you can do what you want with these.\n",
    "# Output to csv or json, send images to your annotation team, seek additional\n",
    "# similar data, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_view.limit(10).tag_samples(\"unique\")\n",
    "dataset.persistent = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.freeze() # screenshot the active App for sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a pre-trained model to compute embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import fiftyone as fo\n",
    "\n",
    "# data_basedir = '/home/lcondados/workspace/data/greiburg_groceries/freiburg_groceries_dataset/images'\n",
    "# dataset = fo.Dataset.from_images_dir(data_basedir, recursive=True, name=\"groceries\")\n",
    "\n",
    "print(dataset)\n",
    "print(dataset.first())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing image embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.brain as fob\n",
    "import fiftyone.zoo as foz\n",
    "\n",
    "# The BDD dataset must be manually downloaded. See the zoo docs for details\n",
    "# source_dir = \"/path/to/dir-with-bdd100k-files\"\n",
    "\n",
    "# dataset = foz.load_zoo_dataset(\n",
    "#     \"bdd100k\", split=\"validation\", source_dir=source_dir,\n",
    "# )\n",
    "\n",
    "# Compute embeddings\n",
    "# You will likely want to run this on a machine with GPU, as this requires\n",
    "# running inference on 10,000 images\n",
    "model = foz.load_zoo_model(\"mobilenet-v2-imagenet-torch\")\n",
    "embeddings = dataset.compute_embeddings(model)\n",
    "\n",
    "# Compute visualization\n",
    "results = fob.compute_visualization(\n",
    "    dataset, embeddings=embeddings, seed=51, brain_key=\"img_viz\"\n",
    ")\n",
    "\n",
    "session = fo.launch_app(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmdet-ssl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
